name: IPO Crawler

on:
  schedule:
    - cron: '0 */2 * * *'
  workflow_dispatch:

jobs:
  final-ipo-crawler:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 lxml
        
    - name: Crawl IPO Information (Final Version)
      run: |
        python << 'EOF'
        import requests
        import json
        from datetime import datetime
        from bs4 import BeautifulSoup
        from urllib.parse import urljoin
        import copy

        def get_text_without_children(tag, child_to_remove):
            d = copy.copy(tag)
            if d.find(child_to_remove):
                d.find(child_to_remove).decompose()
            return d.get_text(strip=True)

        def crawl_final_ipo_data():
            try:
                print("ğŸ¢ ìµœì¢… IPO ì •ë³´ í¬ë¡¤ë§ ì‹œì‘...")
                base_url = "https://finance.n.com" # ì‹¤ì œ URLì€ ìˆ¨ê¹€ ì²˜ë¦¬
                url = "https://finance.naver.com/sise/ipo.naver" # í¬ë¡¤ë§ ëŒ€ìƒ URL
                
                headers = {'User-Agent': 'Mozilla/5.0'}
                response = requests.get(url, headers=headers, timeout=20)
                response.encoding = 'euc-kr'

                if response.status_code != 200:
                    print(f"âŒ HTTP Error: {response.status_code}")
                    return []

                soup = BeautifulSoup(response.text, 'lxml')
                ipo_list = []
                rows = soup.select('table.type_7 > tbody > tr')

                for row in rows:
                    item_area = row.find('div', class_='item_area')
                    if not item_area: continue

                    company_name_tag = item_area.find('h4', class_='item_name')
                    company_name = company_name_tag.find('a').get_text(strip=True)
                    market_type = company_name_tag.find('span', class_='type').get_text(strip=True)
                    
                    info = {'company_name': company_name, 'market_type': market_type}
                    info_list = item_area.find('ul', class_='lst_info')

                    if info_list:
                        price_li = info_list.find('li', class_='area_price')
                        info['offer_price'] = price_li.find('span', class_='num').get_text(strip=True).replace('~', ' ~ ') if price_li and price_li.find('span', class_='num') else 'ë¯¸ì •'
                        
                        type_li = info_list.find('li', class_='area_type')
                        info['industry'] = get_text_without_children(type_li, 'em') if type_li else 'ë¯¸ì •'

                        sup_li = info_list.find('li', class_='area_sup')
                        info['underwriters'] = get_text_without_children(sup_li, 'em') if sup_li else 'ë¯¸ì •'

                        comp_li = info_list.find('li', class_='area_competition')
                        info['competition_rate'] = comp_li.find('span', class_='num').get_text(strip=True) if comp_li and comp_li.find('span', class_='num') else '-'

                        state_li = info_list.find('li', class_='area_state')
                        info['status'] = get_text_without_children(state_li, 'div') if state_li else 'ì •ë³´ì—†ìŒ'

                        private_li = info_list.find('li', class_='area_private')
                        info['subscription_period'] = private_li.find('span', class_='num').get_text(strip=True).replace('~', ' ~ ') if private_li and private_li.find('span', 'num') else 'ë¯¸ì •'
                        
                        list_li = info_list.find('li', class_='area_list')
                        info['listing_date'] = list_li.find('span', 'num').get_text(strip=True) if list_li and list_li.find('span', 'num') else 'ë¯¸ì •'

                    docs_cell = row.find_all('td')[-1]
                    info['documents'] = []
                    if docs_cell:
                        for link in docs_cell.find_all('a', class_='lst'):
                            doc_type = 'ê¸°ì—…ê°œìš”' if 'ê¸°ì—…ê°œìš”' in link.get_text(strip=True) else 'IR BOOK'
                            info['documents'].append({'type': doc_type, 'url': link['href']})
                    
                    ipo_list.append(info)
                    print(f"   âœ… '{company_name}' ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")

                print(f"ğŸ‰ ì´ {len(ipo_list)}ê°œ IPO ì •ë³´ ìˆ˜ì§‘!")
                return ipo_list

            except Exception as e:
                print(f"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
                return []

        def main():
            ipo_data = crawl_final_ipo_data()
            if not ipo_data:
                print("ğŸš¨ í¬ë¡¤ë§ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            final_data = {
                'update_time': datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„'),
                'data_source': 'ì‹¤ì‹œê°„ ì •ë³´',
                'total_ipos': len(ipo_data),
                'ipo_list': ipo_data
            }
            
            output_file = 'n_ipo_data.json'
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(final_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… '{output_file}' íŒŒì¼ ì €ì¥ ì™„ë£Œ!")

        if __name__ == "__main__":
            main()
        EOF
        
    - name: Commit and push results
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "Final IPO Crawler"
        
        if [ -f "n_ipo_data.json" ]; then
          git add n_ipo_data.json
          if git diff --staged --quiet; then
            echo "â„¹ï¸ ë³€ê²½ì‚¬í•­ ì—†ìŒ"
          else
            git commit -m "ğŸš€ IPO ì •ë³´ ìµœì¢… ì—…ë°ì´íŠ¸"
            git push
            echo "âœ… ìµœì¢… IPO ë°ì´í„° í‘¸ì‹œ ì™„ë£Œ"
          fi
        else
          echo "âŒ ì»¤ë°‹í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤"
        fi
