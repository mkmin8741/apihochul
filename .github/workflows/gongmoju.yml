name: KRX Complete IPO Data Crawler (with Details)

on:
  schedule:
    - cron: '0 */3 * * *'  # 3ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰
  workflow_dispatch:

jobs:
  krx-complete-crawler:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 lxml selenium webdriver-manager
        
    - name: Complete KRX IPO Crawler with Details
      run: |
        python << 'EOF'
        import requests
        import json
        from datetime import datetime, timedelta
        import time
        import re
        from bs4 import BeautifulSoup
        from urllib.parse import urlencode, parse_qs, urlparse

        def crawl_krx_ipo_calendar_with_details():
            """KRX IPO ë‹¬ë ¥ + ê° ê¸°ì—… ìƒì„¸ì •ë³´ í¬ë¡¤ë§"""
            try:
                print("ğŸ¢ KRX IPO ì™„ì „ì²´ í¬ë¡¤ë§ ì‹œì‘ (ë‹¬ë ¥ + ìƒì„¸ì •ë³´)...")
                
                current_date = datetime.now()
                all_events = []
                
                # ì´ë²ˆ ë‹¬ê³¼ ë‹¤ìŒ ë‹¬ í¬ë¡¤ë§
                for month_offset in range(2):
                    target_date = current_date.replace(day=1) + timedelta(days=32 * month_offset)
                    year = target_date.year
                    month = target_date.month
                    
                    print(f"ğŸ“… {year}ë…„ {month}ì›” IPO ë‹¬ë ¥ + ìƒì„¸ì •ë³´ í¬ë¡¤ë§...")
                    
                    # KRX ê³µëª¨ì¼ì • ë‹¬ë ¥ URL
                    base_url = "https://kind.krx.co.kr/listinvstg/pubofrschdl.do"
                    params = {
                        'method': 'searchPubofrScholMain'
                    }
                    
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                        'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
                        'Connection': 'keep-alive',
                        'Referer': 'https://kind.krx.co.kr/'
                    }
                    
                    try:
                        response = requests.get(base_url, params=params, headers=headers, timeout=20)
                        
                        if response.status_code == 200:
                            response.encoding = 'utf-8'
                            soup = BeautifulSoup(response.text, 'html.parser')
                            
                            # ë‹¬ë ¥ì—ì„œ ê¸°ì—… ë§í¬ë“¤ ì°¾ê¸°
                            company_links = soup.find_all('a', href=True)
                            
                            for link in company_links:
                                href = link.get('href')
                                company_name = link.get_text().strip()
                                
                                # ê³µëª¨ê¸°ì—… ìƒì„¸ ë§í¬ì¸ì§€ í™•ì¸
                                if 'pubofrprogcomdetail.do' in href and company_name and len(company_name) > 1:
                                    # ìƒì„¸ ì •ë³´ í¬ë¡¤ë§
                                    detail_info = get_company_detail_info(href, company_name, headers)
                                    if detail_info:
                                        all_events.append(detail_info)
                                        print(f"   âœ… {company_name} ìƒì„¸ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
                                        time.sleep(2)  # ì„œë²„ ë¶€í•˜ ë°©ì§€
                        
                        time.sleep(3)
                        
                    except Exception as e:
                        print(f"   âŒ {year}-{month:02d} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
                        continue
                
                return all_events
                
            except Exception as e:
                print(f"âŒ ì „ì²´ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
                return []

        def get_company_detail_info(detail_url, company_name, headers):
            """ê°œë³„ ê³µëª¨ê¸°ì—… ìƒì„¸ì •ë³´ í¬ë¡¤ë§"""
            try:
                # ìƒëŒ€ URLì„ ì ˆëŒ€ URLë¡œ ë³€í™˜
                if detail_url.startswith('javascript:'):
                    return None
                
                if not detail_url.startswith('http'):
                    detail_url = 'https://kind.krx.co.kr' + detail_url
                
                response = requests.get(detail_url, headers=headers, timeout=15)
                response.encoding = 'utf-8'
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # ìƒì„¸ì •ë³´ ì¶”ì¶œ
                detail_data = {
                    'company_name': company_name,
                    'detail_url': detail_url,
                    'crawl_time': datetime.now().isoformat(),
                    'source': 'KRX KIND ê³µëª¨ê¸°ì—… ìƒì„¸'
                }
                
                # í…Œì´ë¸”ì—ì„œ ì •ë³´ ì¶”ì¶œ
                tables = soup.find_all('table')
                
                for table in tables:
                    rows = table.find_all('tr')
                    
                    for row in rows:
                        cells = row.find_all(['td', 'th'])
                        
                        if len(cells) >= 2:
                            for i in range(0, len(cells)-1, 2):
                                key = cells[i].get_text().strip()
                                value = cells[i+1].get_text().strip()
                                
                                # ì£¼ìš” ì •ë³´ ë§¤í•‘
                                if key == 'ì„¤ë¦½ì¼':
                                    detail_data['establishment_date'] = value
                                elif key == 'ëŒ€í‘œì´ì‚¬':
                                    detail_data['ceo'] = value
                                elif key == 'ì—…ì¢…':
                                    detail_data['industry'] = value
                                elif key == 'ì£¼ìš”ì œí’ˆ':
                                    detail_data['main_products'] = value
                                elif key == 'ë§¤ì¶œì•¡(ìˆ˜ìµ)':
                                    detail_data['revenue'] = value
                                elif key == 'ìˆœì´ìµ':
                                    detail_data['net_income'] = value
                                elif key == 'ìê¸°ìë³¸':
                                    detail_data['equity'] = value
                                elif key == 'ìµœëŒ€ì£¼ì£¼':
                                    detail_data['major_shareholder'] = value
                                elif key == 'ìµœëŒ€ì£¼ì£¼ ì§€ë¶„ìœ¨':
                                    detail_data['ownership_ratio'] = value
                                elif key == 'IRì¼ì •':
                                    detail_data['ir_schedule'] = value
                                elif key == 'ìˆ˜ìš”ì˜ˆì¸¡ì¼ì •':
                                    detail_data['demand_forecast_schedule'] = value
                                elif key == 'ê³µëª¨ì²­ì•½ì¼ì •':
                                    detail_data['subscription_schedule'] = value
                                elif key == 'ìƒì¥(ì˜ˆì •)ì¼':
                                    detail_data['listing_date'] = value
                                elif key == 'í¬ë§ê³µëª¨ê°€ê²©':
                                    detail_data['hoped_price'] = value
                                elif key == 'ì•¡ë©´ê°€':
                                    detail_data['par_value'] = value
                
                # ë‚ ì§œ ì •ë³´ íŒŒì‹± (ìƒì¥ì˜ˆì •ì¼ì—ì„œ)
                if 'listing_date' in detail_data:
                    listing_date = detail_data['listing_date']
                    date_match = re.search(r'(\d{4}-\d{2}-\d{2})', listing_date)
                    if date_match:
                        detail_data['date'] = date_match.group(1)
                        detail_data['event_type'] = 'ìƒì¥ì˜ˆì •'
                    else:
                        detail_data['date'] = datetime.now().strftime('%Y-%m-%d')
                        detail_data['event_type'] = 'ì •ë³´ìˆ˜ì§‘'
                else:
                    detail_data['date'] = datetime.now().strftime('%Y-%m-%d')
                    detail_data['event_type'] = 'ì •ë³´ìˆ˜ì§‘'
                
                # ì‹œì¥ êµ¬ë¶„ ì¶”ì •
                detail_data['market_type'] = determine_market_type(company_name, detail_data.get('industry', ''))
                
                return detail_data
                
            except Exception as e:
                print(f"   âŒ {company_name} ìƒì„¸ì •ë³´ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
                return None

        def determine_market_type(company_name, industry):
            """íšŒì‚¬ëª…ê³¼ ì—…ì¢…ìœ¼ë¡œ ì‹œì¥ êµ¬ë¶„ ì¶”ì •"""
            if 'SPAC' in company_name.upper() or 'ìŠ¤íŒ©' in company_name:
                return 'ì½”ìŠ¤ë‹¥'
            elif any(keyword in industry for keyword in ['ë°”ì´ì˜¤', 'ì˜ë£Œ', 'ì†Œí”„íŠ¸ì›¨ì–´', 'IT', 'ê²Œì„']):
                return 'ì½”ìŠ¤ë‹¥'
            elif any(keyword in company_name for keyword in ['ì¡°ì„ ', 'ì¤‘ê³µì—…', 'ì „ì', 'í™”í•™']):
                return 'ìœ ê°€ì¦ê¶Œ'
            else:
                return 'ì½”ìŠ¤ë‹¥'  # ê¸°ë³¸ê°’

        def categorize_events_by_date(events):
            """ë‚ ì§œë³„ ì´ë²¤íŠ¸ ë¶„ë¥˜"""
            today = datetime.now().date()
            
            categorized = {
                'today_events': [],
                'tomorrow_events': [],
                'week_events': [],
                'month_events': [],
                'upcoming_events': [],
                'by_type': {
                    'ìƒì¥ì˜ˆì •': [],
                    'ì •ë³´ìˆ˜ì§‘': [],
                    'IR': [],
                    'ìˆ˜ìš”ì˜ˆì¸¡': [],
                    'ì²­ì•½': []
                }
            }
            
            for event in events:
                try:
                    event_date = datetime.strptime(event['date'], '%Y-%m-%d').date()
                    days_diff = (event_date - today).days
                    
                    # ë‚ ì§œë³„ ë¶„ë¥˜
                    if days_diff == 0:
                        categorized['today_events'].append(event)
                    elif days_diff == 1:
                        categorized['tomorrow_events'].append(event)
                    elif 2 <= days_diff <= 7:
                        categorized['week_events'].append(event)
                    elif 8 <= days_diff <= 30:
                        categorized['month_events'].append(event)
                    elif days_diff > 30:
                        categorized['upcoming_events'].append(event)
                    
                    # íƒ€ì…ë³„ ë¶„ë¥˜
                    event_type = event['event_type']
                    if event_type in categorized['by_type']:
                        categorized['by_type'][event_type].append(event)
                        
                except Exception as e:
                    print(f"   âŒ ì´ë²¤íŠ¸ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            
            return categorized

        def extract_financial_summary(events):
            """ì¬ë¬´ ìš”ì•½ ì •ë³´ ìƒì„±"""
            financial_summary = {
                'total_companies': len(events),
                'profitable_companies': 0,
                'loss_companies': 0,
                'average_revenue': 0,
                'by_industry': {},
                'by_market': {}
            }
            
            total_revenue = 0
            revenue_count = 0
            
            for event in events:
                # ìˆ˜ìµì„± ë¶„ì„
                if 'net_income' in event:
                    net_income = event['net_income']
                    if '-' in net_income:
                        financial_summary['loss_companies'] += 1
                    else:
                        financial_summary['profitable_companies'] += 1
                
                # ë§¤ì¶œì•¡ í‰ê·  ê³„ì‚°
                if 'revenue' in event:
                    revenue_text = event['revenue']
                    revenue_numbers = re.findall(r'[\d,]+', revenue_text.replace(',', ''))
                    if revenue_numbers:
                        try:
                            revenue = int(revenue_numbers[0])
                            total_revenue += revenue
                            revenue_count += 1
                        except:
                            pass
                
                # ì—…ì¢…ë³„ ë¶„ë¥˜
                industry = event.get('industry', 'ê¸°íƒ€')
                financial_summary['by_industry'][industry] = financial_summary['by_industry'].get(industry, 0) + 1
                
                # ì‹œì¥ë³„ ë¶„ë¥˜
                market = event.get('market_type', 'ê¸°íƒ€')
                financial_summary['by_market'][market] = financial_summary['by_market'].get(market, 0) + 1
            
            if revenue_count > 0:
                financial_summary['average_revenue'] = total_revenue // revenue_count
            
            return financial_summary

        def main():
            print('ğŸ¢ KRX IPO ì™„ì „ì²´ í¬ë¡¤ë§ ì‹œìŠ¤í…œ ì‹œì‘...')
            
            # ë‹¬ë ¥ + ìƒì„¸ì •ë³´ ì™„ì „ í¬ë¡¤ë§
            events = crawl_krx_ipo_calendar_with_details()
            
            if not events:
                print("âŒ í¬ë¡¤ë§ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                # ê¸°ë³¸ ë°ì´í„° ìƒì„±
                events = [{
                    'company_name': 'KRX í¬ë¡¤ë§ ì§„í–‰ì¤‘',
                    'date': datetime.now().strftime('%Y-%m-%d'),
                    'event_type': 'ì‹œìŠ¤í…œ',
                    'market_type': 'ì‹œìŠ¤í…œ',
                    'source': 'KRX ì™„ì „ì²´ í¬ë¡¤ë§'
                }]
            
            # ì´ë²¤íŠ¸ ë¶„ë¥˜
            categorized = categorize_events_by_date(events)
            
            # ì¬ë¬´ ìš”ì•½ ì •ë³´
            financial_summary = extract_financial_summary(events)
            
            # í†µê³„ ìƒì„±
            stats = {
                'total_events': len(events),
                'today_count': len(categorized['today_events']),
                'tomorrow_count': len(categorized['tomorrow_events']),
                'week_count': len(categorized['week_events']),
                'month_count': len(categorized['month_events']),
                'upcoming_count': len(categorized['upcoming_events']),
                'by_type_count': {k: len(v) for k, v in categorized['by_type'].items()},
                'financial_summary': financial_summary
            }
            
            # ìµœì¢… JSON ë°ì´í„°
            final_data = {
                'update_time': datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„'),
                'crawl_time': datetime.now().isoformat(),
                'data_source': 'KRX KIND ì™„ì „ì²´ í¬ë¡¤ë§ (ë‹¬ë ¥ + ìƒì„¸ì •ë³´)',
                'crawl_method': 'GitHub Actions + ì™„ì „ ìë™í™” + ìƒì„¸ì •ë³´',
                'source_url': 'https://kind.krx.co.kr/listinvstg/pubofrschdl.do?method=searchPubofrScholMain',
                'detail_crawling': True,
                'total_events': len(events),
                'statistics': stats,
                'categorized_events': categorized,
                'all_events': events,
                'status': 'success' if len(events) > 1 else 'limited_data'
            }
            
            # JSON íŒŒì¼ ì €ì¥
            output_file = 'ipo_complete_data.json'
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(final_data, f, ensure_ascii=False, indent=2)
                print(f'âœ… {output_file} íŒŒì¼ ìƒì„± ì™„ë£Œ')
                
            except Exception as e:
                print(f'âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}')
                raise
            
            # ê²°ê³¼ ì¶œë ¥
            print(f'\nğŸ‰ KRX IPO ì™„ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ!')
            print(f'ğŸ”— ì†ŒìŠ¤: KRX KIND ê³µëª¨ê¸°ì—… ìƒì„¸ì •ë³´')
            print(f'ğŸ“Š ì´ ê¸°ì—…: {len(events)}ê°œ')
            print(f'ğŸ’° í‰ê·  ë§¤ì¶œ: {stats["financial_summary"]["average_revenue"]:,}ë°±ë§Œì›')
            print(f'ğŸ“ˆ í‘ì ê¸°ì—…: {stats["financial_summary"]["profitable_companies"]}ê°œ')
            print(f'ğŸ“‰ ì ì ê¸°ì—…: {stats["financial_summary"]["loss_companies"]}ê°œ')
            print(f'ğŸ›ï¸ ì‹œì¥ë³„: {stats["financial_summary"]["by_market"]}')
            print(f'ğŸ­ ì—…ì¢…ë³„: {list(stats["financial_summary"]["by_industry"].keys())[:5]}')
            
        if __name__ == "__main__":
            main()
        EOF
        
    - name: Commit and push
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "KRX Complete IPO Crawler"
        
        if [ -f "ipo_complete_data.json" ]; then
          git add ipo_complete_data.json
          if git diff --staged --quiet; then
            echo "â„¹ï¸ ë³€ê²½ì‚¬í•­ ì—†ìŒ"
          else
            git commit -m "ğŸ¢ KRX IPO ì™„ì „ì²´ í¬ë¡¤ë§ (ë‹¬ë ¥+ìƒì„¸ì •ë³´) $(date +'%Y-%m-%d %H:%M')"
            git push
            echo "âœ… ì™„ì „ì²´ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ"
          fi
        fi
