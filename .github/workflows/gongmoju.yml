name: IPO Calendar Crawler (Real Structure)

on:
  schedule:
    - cron: '0 */2 * * *'
  workflow_dispatch:

jobs:
  ipo-crawl:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 lxml selenium webdriver-manager
        
    - name: Real structure crawling
      run: |
        python << 'EOF'
        import requests
        import json
        from datetime import datetime, timedelta
        import time
        import re
        from bs4 import BeautifulSoup

        def parse_company_id(onclick_text):
            """fnDetailViewì—ì„œ íšŒì‚¬ ID ì¶”ì¶œ"""
            try:
                if 'fnDetailView' in onclick_text:
                    match = re.search(r"fnDetailView\('([^']+)'\)", onclick_text)
                    if match:
                        return match.group(1)
                return None
            except:
                return None

        def get_market_type(img_src):
            """ì‹œìž¥ êµ¬ë¶„ íŒŒì•…"""
            if 'icn_t_yu.gif' in img_src:
                return 'ìœ ê°€ì¦ê¶Œ'
            elif 'icn_t_ko.gif' in img_src:
                return 'ì½”ìŠ¤ë‹¥'
            else:
                return 'ê¸°íƒ€'

        def crawl_38_calendar():
            """38ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë‹¬ë ¥ íŽ˜ì´ì§€ í¬ë¡¤ë§ (ì‹¤ì œ êµ¬ì¡° ê¸°ë°˜)"""
            try:
                print("ðŸ¢ 38ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë‹¬ë ¥ í¬ë¡¤ë§ ì‹œìž‘...")
                
                # í˜„ìž¬ ì›”ê³¼ ë‹¤ìŒ ì›” í¬ë¡¤ë§
                current_date = datetime.now()
                urls = []
                
                # ì´ë²ˆ ë‹¬, ë‹¤ìŒ ë‹¬ URL ìƒì„±
                for i in range(2):
                    target_date = current_date + timedelta(days=30*i)
                    year = target_date.year
                    month = target_date.month
                    url = f"http://www.38.co.kr/html/fund/index.html?o=k&year={year}&month={month:02d}"
                    urls.append((url, f"{year}-{month:02d}"))
                
                all_events = []
                
                for url, date_str in urls:
                    print(f"ðŸ“… {date_str} ë‹¬ë ¥ í¬ë¡¤ë§...")
                    
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                        'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
                        'Accept-Encoding': 'gzip, deflate',
                        'Connection': 'keep-alive',
                        'Upgrade-Insecure-Requests': '1',
                    }
                    
                    try:
                        response = requests.get(url, headers=headers, timeout=15)
                        response.raise_for_status()
                        response.encoding = 'euc-kr'  # í•œê¸€ ê¹¨ì§ ë°©ì§€
                        
                        soup = BeautifulSoup(response.text, 'html.parser')
                        
                        # calBig2 í…Œì´ë¸” ì°¾ê¸°
                        calendar_div = soup.find('div', {'id': 'calBig2'})
                        if not calendar_div:
                            print(f"   âŒ {date_str} ë‹¬ë ¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                            continue
                        
                        # í…Œì´ë¸” ë‚´ì˜ ëª¨ë“  ë‚ ì§œ ì…€ ì²˜ë¦¬
                        table = calendar_div.find('table')
                        if table:
                            cells = table.find_all('td')
                            
                            for cell in cells:
                                # ë‚ ì§œ ì¶”ì¶œ
                                day_text = cell.get_text().strip()
                                if not day_text or not day_text.isdigit():
                                    continue
                                
                                day = int(day_text)
                                full_date = f"{date_str}-{day:02d}"
                                
                                # í•´ë‹¹ ë‚ ì§œì˜ ì´ë²¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸°
                                ul = cell.find('ul')
                                if not ul:
                                    continue
                                
                                # ì´ë²¤íŠ¸ íƒ€ìž…ê³¼ íšŒì‚¬ ì •ë³´ íŒŒì‹±
                                li_elements = ul.find_all('li')
                                current_event_type = None
                                
                                for li in li_elements:
                                    # ì´ë²¤íŠ¸ íƒ€ìž…ì¸ì§€ í™•ì¸ (ë°°ê²½ìƒ‰ì´ ìžˆëŠ” ê²½ìš°)
                                    style = li.get('style', '')
                                    if 'background:#EBF6F8' in style:
                                        strong = li.find('strong')
                                        if strong:
                                            current_event_type = strong.get_text().strip()
                                            continue
                                    
                                    # íšŒì‚¬ ë§í¬ì¸ì§€ í™•ì¸
                                    link = li.find('a')
                                    if link and current_event_type:
                                        onclick = link.get('onclick', '')
                                        company_id = parse_company_id(onclick)
                                        
                                        if company_id:
                                            # íšŒì‚¬ëª… ì¶”ì¶œ
                                            company_name = link.get_text().strip()
                                            
                                            # ì‹œìž¥ êµ¬ë¶„ ì¶”ì¶œ
                                            img = link.find('img')
                                            market_type = get_market_type(img.get('src', '')) if img else 'ê¸°íƒ€'
                                            
                                            event_data = {
                                                'date': full_date,
                                                'day': day,
                                                'event_type': current_event_type,
                                                'company_name': company_name,
                                                'company_id': company_id,
                                                'market_type': market_type,
                                                'source_url': url,
                                                'crawl_time': datetime.now().isoformat()
                                            }
                                            
                                            all_events.append(event_data)
                                            print(f"   âœ… {full_date} {current_event_type}: {company_name} ({market_type})")
                        
                        time.sleep(2)  # ì„œë²„ ë¶€í•˜ ë°©ì§€
                        
                    except Exception as e:
                        print(f"   âŒ {date_str} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
                        continue
                
                return all_events
                
            except Exception as e:
                print(f"âŒ ë‹¬ë ¥ í¬ë¡¤ë§ ì „ì²´ ì‹¤íŒ¨: {e}")
                return []

        def get_detailed_info(company_id):
            """íšŒì‚¬ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘"""
            try:
                detail_url = f"http://www.38.co.kr/html/fund/index.html?o=k&no={company_id}"
                
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Referer': 'http://www.38.co.kr/'
                }
                
                response = requests.get(detail_url, headers=headers, timeout=10)
                response.encoding = 'euc-kr'
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # ìƒì„¸ ì •ë³´ íŒŒì‹± (ì‹¤ì œ íŽ˜ì´ì§€ êµ¬ì¡°ì— ë”°ë¼ ì¡°ì •)
                detail_info = {
                    'price_range': '',
                    'confirmed_price': '',
                    'subscription_date': '',
                    'listing_date': '',
                    'underwriter': '',
                    'business_type': ''
                }
                
                # ì—¬ê¸°ì„œ ì‹¤ì œ ìƒì„¸ íŽ˜ì´ì§€ êµ¬ì¡°ì— ë§žì¶° ì •ë³´ ì¶”ì¶œ
                # (íŽ˜ì´ì§€ êµ¬ì¡°ë¥¼ ë³´ê³  ì¶”ê°€ ê°œë°œ í•„ìš”)
                
                return detail_info
                
            except:
                return {}

        def categorize_events(events):
            """ì´ë²¤íŠ¸ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜"""
            categorized = {
                'ì˜¤ëŠ˜_ì´ë²¤íŠ¸': [],
                'ì´ë²ˆì£¼_ì´ë²¤íŠ¸': [],
                'ë‹¤ìŒì£¼_ì´ë²¤íŠ¸': [],
                'ìƒìž¥_ì˜ˆì •': [],
                'IR_ì¼ì •': [],
                'ìˆ˜ìš”ì˜ˆì¸¡': [],
                'ê¸°íƒ€': []
            }
            
            today = datetime.now().date()
            
            for event in events:
                try:
                    event_date = datetime.strptime(event['date'], '%Y-%m-%d').date()
                    days_diff = (event_date - today).days
                    
                    # ë‚ ì§œë³„ ë¶„ë¥˜
                    if days_diff == 0:
                        categorized['ì˜¤ëŠ˜_ì´ë²¤íŠ¸'].append(event)
                    elif 0 < days_diff <= 7:
                        categorized['ì´ë²ˆì£¼_ì´ë²¤íŠ¸'].append(event)
                    elif 7 < days_diff <= 14:
                        categorized['ë‹¤ìŒì£¼_ì´ë²¤íŠ¸'].append(event)
                    
                    # ì´ë²¤íŠ¸ íƒ€ìž…ë³„ ë¶„ë¥˜
                    event_type = event['event_type']
                    if 'ìƒìž¥' in event_type:
                        categorized['ìƒìž¥_ì˜ˆì •'].append(event)
                    elif 'IR' in event_type:
                        categorized['IR_ì¼ì •'].append(event)
                    elif 'ìˆ˜ìš”ì˜ˆì¸¡' in event_type:
                        categorized['ìˆ˜ìš”ì˜ˆì¸¡'].append(event)
                    else:
                        categorized['ê¸°íƒ€'].append(event)
                        
                except:
                    categorized['ê¸°íƒ€'].append(event)
            
            return categorized

        def main():
            print('ðŸ¢ 38ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì‹¤ì œ êµ¬ì¡° ê¸°ë°˜ í¬ë¡¤ë§ ì‹œìž‘...')
            
            # ë‹¬ë ¥ì—ì„œ ì´ë²¤íŠ¸ ìˆ˜ì§‘
            events = crawl_38_calendar()
            print(f"ðŸ“Š ì´ {len(events)}ê°œ ì´ë²¤íŠ¸ ìˆ˜ì§‘")
            
            # ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (ì£¼ìš” ì´ë²¤íŠ¸ë§Œ)
            important_events = [e for e in events if e['event_type'] in ['ìƒìž¥', 'ìˆ˜ìš”ì˜ˆì¸¡']]
            for event in important_events[:5]:  # ì²˜ë¦¬ëŸ‰ ì œí•œ
                detail_info = get_detailed_info(event['company_id'])
                event.update(detail_info)
                time.sleep(1)
            
            # ì´ë²¤íŠ¸ ë¶„ë¥˜
            categorized_events = categorize_events(events)
            
            # ìµœì¢… JSON ìƒì„±
            final_data = {
                'updateTime': datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„'),
                'crawlTime': datetime.now().isoformat(),
                'totalEvents': len(events),
                'dataSource': '38ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë‹¬ë ¥ (ì‹¤ì œêµ¬ì¡°ê¸°ë°˜)',
                'crawlingMethod': 'HTMLë‹¬ë ¥íŒŒì‹± + ìƒì„¸ì •ë³´ìˆ˜ì§‘',
                'summary': {
                    'ì˜¤ëŠ˜_ì´ë²¤íŠ¸_ìˆ˜': len(categorized_events['ì˜¤ëŠ˜_ì´ë²¤íŠ¸']),
                    'ì´ë²ˆì£¼_ì´ë²¤íŠ¸_ìˆ˜': len(categorized_events['ì´ë²ˆì£¼_ì´ë²¤íŠ¸']),
                    'ìƒìž¥_ì˜ˆì •_ìˆ˜': len(categorized_events['ìƒìž¥_ì˜ˆì •']),
                    'IR_ì¼ì •_ìˆ˜': len(categorized_events['IR_ì¼ì •']),
                    'ìˆ˜ìš”ì˜ˆì¸¡_ìˆ˜': len(categorized_events['ìˆ˜ìš”ì˜ˆì¸¡'])
                },
                'categorized_events': categorized_events,
                'all_events': events
            }
            
            # JSON ì €ìž¥
            with open('ipo_calendar.json', 'w', encoding='utf-8') as f:
                json.dump(final_data, f, ensure_ascii=False, indent=2)
                
            print(f'\nðŸŽ‰ ì‹¤ì œ êµ¬ì¡° ê¸°ë°˜ í¬ë¡¤ë§ ì™„ë£Œ!')
            print(f'ðŸ“Š ì´ {len(events)}ê°œ ì´ë²¤íŠ¸')
            print(f'ðŸ“… ì˜¤ëŠ˜ ì´ë²¤íŠ¸: {len(categorized_events["ì˜¤ëŠ˜_ì´ë²¤íŠ¸"])}ê°œ')
            print(f'ðŸ“ˆ ìƒìž¥ ì˜ˆì •: {len(categorized_events["ìƒìž¥_ì˜ˆì •"])}ê°œ')
            print(f'ðŸ¢ IR ì¼ì •: {len(categorized_events["IR_ì¼ì •"])}ê°œ')
            print(f'ðŸ“Š ìˆ˜ìš”ì˜ˆì¸¡: {len(categorized_events["ìˆ˜ìš”ì˜ˆì¸¡"])}ê°œ')
            
        if __name__ == "__main__":
            main()
        EOF
        
    - name: Commit and push
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "IPO Calendar Crawler"
        git add ipo_calendar.json
        if git diff --staged --quiet; then
          echo "ë³€ê²½ì‚¬í•­ ì—†ìŒ"
        else
          git commit -m "ðŸ¢ ì‹¤ì œêµ¬ì¡° ê¸°ë°˜ ê³µëª¨ì£¼ ë‹¬ë ¥ í¬ë¡¤ë§ $(date +'%Y-%m-%d %H:%M')"
          git push
          echo "âœ… ì‹¤ì œ êµ¬ì¡° ê¸°ë°˜ ë°ì´í„° ì—…ë¡œë“œ"
        fi
